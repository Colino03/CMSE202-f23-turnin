{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: right;\"> &#9989; Colin Bonnema </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSE 202 Final (Section 001 - Fall 2023)\n",
    "\n",
    "The goal of this final is to give you the opportunity to test out some of the skills that you've developed having now finished CMSE 202. In particular, you'll be committing and pushing repository changes to a GitHub repository, working with data to build a network graph, performing regression analysis, and classifying data using a machine learning classifier. You should find that you have all of the skills necessary to complete this exam having completed the second half of CMSE 202!\n",
    "\n",
    "You are encouraged to look through the entire exam before you get started so that you can appropriately budget your time and understand the broad goals of the exam. Once you've read through it, you'll probably want to make sure you do Part 1 first to ensure that your GitHub repository is working correctly. Let your instructor know right away if you run into issues!\n",
    "\n",
    "The exam is set up so that even if you get stuck on one part there are opportunities to get points on the other parts, so consider jumping ahead if you feel like you aren't making progress and then come back later if you have time.\n",
    "\n",
    "**Important note about using online resources**: This exam is \"open internet\". That means that you can look up documentation, google how to accomplish certain Python tasks, etc. Being able to effectively use the internet for computational modeling and data science is a very important skill, so we want to make sure you have the opportunity to exercise that skill. **However**: The use of any person-to-person communication software is absolutely not acceptable. If you are seen accessing your email, using a chat program (e.g. Slack), or any sort of collaborative cloud storage or document software (e.g. Google Documents), you will be at risk for receiving a zero on the exam.\n",
    "\n",
    "**You can also use _your version_ of past CMSE 202 assignments and the CMSE 202 course materials as a resource!**\n",
    "\n",
    "You can also use any publicly available generative AI tool, if you find such a tool to be useful, **but you must properly cite the tool in your exam submission if you do so**.\n",
    "\n",
    "**Keep your eyes on your screen!** Unfortunately, there isn't enough space in the room for everyone to sit at their own table so please do your best to keep your eyes on your own screen. This exam is designed to give *you* the opportunity to show the instructor what you can do and you should hold yourself accountable for maintaining a high level of academic integrity. If any of the instructors observe suspicious behavior, you will, again, risk receiving a zero. If you're completing the exam virtually, the same standards of academic integrity apply!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 0: Academic integrity statement\n",
    "\n",
    "Read the following statement and edit the markdown text to put your name in the statement. This is your commitment to doing your own authentic work on this exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I, **Colin Bonnema**, affirm that this exam represents my own authetic work, without the use of any unpermitted aids or resources or person-to-person communication. I understand that this exam an an opportunity to showcase my own progress in developing and improving my computational skills and have done my best to demonstrate those skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Add to your Git repository to track your progress on your exam (2 points)\n",
    "\n",
    "Before you get to far along in the exam, you're going to add it to the `cmse202-f23-turnin` repository you created in class so that you can track your progress on the exam and preserve the final version that you turn in. In order to do this you need to\n",
    "\n",
    "**&#9989; Do the following**:\n",
    "\n",
    "1. Navigate to your `cmse202-f23-turnin` repository and create a new directory called `final`.\n",
    "2. Move this notebook into that **new directory** in your repository, then **add it and commit it to your repository**.\n",
    "1. Finally, to test that everything is working, \"git push\" the file so that it ends up in your GitHub repository.\n",
    "\n",
    "**Important**: Double check you've added your Professor and your TA as collaborators to your \"turnin\" respository (you should have done this in the previous homework assignment).\n",
    "\n",
    "**Also important**: Make sure that the version of this notebook that you are working on is the same one that you just added to your repository! If you are working on a different copy of the noteobok, **none of your changes will be tracked**!\n",
    "\n",
    "If everything went as intended, the file should now show up on your GitHub account in the \"`cmse202-f23-turnin`\" repository inside the `final` directory that you just created.  Periodically, **you'll be asked to commit your changes to the repository and push them to the remote GitHub location**. Of course, you can always commit your changes more often than that, if you wish.  It can be good to get into a habit of committing your changes any time you make a significant modification, or when you stop working on the project for a bit.\n",
    "\n",
    "&#9989; **Question 1.1 (2 points)**: **Do this**: Before you move on, put the command that your instructor should run to clone your repository in the markdown cell below. Also make sure that you created the directory and pushed your change to GitHub as explained above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "# git clone https://github.com/Colino03/CMSE202-f23-turnin.git\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Generate a network graph from data (16 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the exam, we will look at characters in the Marvel comic book universe. The Marvel universe features a large number of characters that have appeared in a large number of comics over the years. Some of them appear with each other, while others never meet. We will model these character co-appearances as an undirected graph. Every node will be a character and there will be a edge between two characters if they co-appeared in a comic book. The dataset originally comes from [here](https://github.com/melaniewalsh/sample-social-network-datasets/tree/master/sample-datasets/marvel).\n",
    "\n",
    "You can find a copy of the relevant data file here:\n",
    "\n",
    "`https://raw.githubusercontent.com/msu-cmse-courses/cmse202-supplemental-data/main/data/marvel-unimodal-edges.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.1 (3 points)**: To get started, **download the `.csv` file and place it in the same directory as your notebook**, then **read in the `marvel-unimodal-edges.csv` dataset** and finally **display the first few rows of the data**. You can use **Pandas** for this task or any other Python tool you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Source                   Target  Weight\n",
      "0   Black Panther / T'chal         Loki [asgardian]      10\n",
      "1   Black Panther / T'chal        Mantis / ? Brandt      23\n",
      "2   Black Panther / T'chal    Iceman / Robert Bobby      12\n",
      "3   Black Panther / T'chal  Marvel Girl / Jean Grey      10\n",
      "4   Black Panther / T'chal   Cyclops / Scott Summer      14\n",
      "5   Black Panther / T'chal      Klaw / Ulysses Klaw      17\n",
      "6   Black Panther / T'chal   Human Torch / Johnny S      44\n",
      "7   Black Panther / T'chal     Richards, Franklin B       6\n",
      "8   Black Panther / T'chal        Wolverine / Logan       9\n",
      "9   Black Panther / T'chal   Firebird / Bonita Juar       7\n",
      "10  Black Panther / T'chal   Mr. Fantastic / Reed R      41\n",
      "11  Black Panther / T'chal   Medusa / Medusalith Am      16\n",
      "12  Black Panther / T'chal    Dr. Strange / Stephen      23\n",
      "13  Black Panther / T'chal    Jack Of Hearts / Jack       5\n",
      "14  Black Panther / T'chal                 Mephisto       7\n"
     ]
    }
   ],
   "source": [
    "### Put your code here\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"marvel-unimodal-edges.csv\")\n",
    "result = df.head(15)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see three columns: `Source`, `Target`, and `Weight`. We are going to ignore `Weight` in this exam (it is the number of times two characters co-appear in the comics). `Source` and `Target` are the two (unique) character names that co-appear. We will now create a `networkx` graph using this dataset.\n",
    "\n",
    "&#9989; **Question 2.2 (4 points)**: **Create an undirected `networkx` graph** (you can call it `G`). Make sure it is a undirected graph. Then, iterate over the dataset and **add edges between the `source` and `target` characters** on each line. Ignore the weights. (The resulting graph should now have an edge per entry in the dataset and the set of all names should be the set of all nodes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f6e693ee2e1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Source\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36madd_edges_from\u001b[0;34m(self, ebunch_to_add, **attr)\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNetworkXError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Edge tuple {e} must be a 2-tuple or 3-tuple.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjlist_inner_dict_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_attr_dict_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Series'"
     ]
    }
   ],
   "source": [
    "### Put your code here\n",
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(df['Target'])\n",
    "G.add_edges_from([(df[\"Source\"],df[\"Target\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now visualize the graph.\n",
    "\n",
    "&#9989; **Question 2.3 (5 points)**: Create a large figure for drawing the graph using something like `plt.figure(figsize=(20,20))`. Then, draw the graph using `networkx`. Make sure that when drawing your graph, you accomplish the following:\n",
    "1. The `\"Captain America\"` node should have a unique node color, he's the most connected character,\n",
    "2. The characters `\"Asp Ii / Cleo\"` and `\"Black Mamba / Tanya Se\"` should have the same color as each other, but it should be _different_ color from that of Captain America.\n",
    "3. All of the other characters should have a third, different color.\n",
    "\n",
    "To recap, you should have **three** different colors in your graph, one for Captain America, one for Asp and Black Mamba, and one for all of the other characters.\n",
    "\n",
    "(Partial credit if you generate the graph but the colors are not set as described.)\n",
    "\n",
    "**Note**: this will be a very crowded graph because it's a complex, heavily-interconnected network, but you should see that Captain America is somewhere in the middle of the graph and that Asp and Black Mamba are connected to each other and on the outskirts of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using **only the graph you created (not the initial row-based data)**, answer the following questions.\n",
    "\n",
    "You may find it useful to review the \"Methods\" section of the [networkx Graph documentation](https://networkx.org/documentation/stable/reference/classes/graph.html#methods).\n",
    "\n",
    "&#9989; **Question 2.4 (1 point)** What is the number of characters appearing in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.5 (1 point)** With how many characters does `\"Vision\"` co-appear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.6 (1 point)** True or False?: `\"Hyperion\"` co-appears with `\"Hammerhead\"`. Use a graph method to determine this. If you want to verify that you're right, you could create a new visualization of your graph and give these two characters unique colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.7 (1 point)** Using the relevant `networkx` function (consult the documentation/internet resources), **find the \"shortest path\" between `\"Sif\"` and `\"Callisto\"`**. The two characters do not appear together, but you should be able to determine a set of nodes to \"traverse\" to get from one character to the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 2**\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Perform a regression analysis on data (16 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now be looking at a dataset of diamonds of varying properties and qualities and their prices. You can find the dataset to download here:\n",
    "\n",
    "`https://raw.githubusercontent.com/msu-cmse-courses/cmse202-supplemental-data/main/data/diamonds.csv`\n",
    "\n",
    "&#9989; **Question 3.1 (2 points)**: To get started, **download the `diamonds.csv` file and place it in the same directory as your notebook**, then **read in the `diamonds.csv` dataset** and finally **display the first few rows of the data**. You can use **Pandas** for this task or any other Python tool you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    carat        cut color clarity  depth  table  price     x     y     z\n",
      "0    0.23      Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
      "1    0.21    Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
      "2    0.23       Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
      "3    0.29    Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
      "4    0.31       Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n",
      "5    0.24  Very Good     J    VVS2   62.8   57.0    336  3.94  3.96  2.48\n",
      "6    0.24  Very Good     I    VVS1   62.3   57.0    336  3.95  3.98  2.47\n",
      "7    0.26  Very Good     H     SI1   61.9   55.0    337  4.07  4.11  2.53\n",
      "8    0.22       Fair     E     VS2   65.1   61.0    337  3.87  3.78  2.49\n",
      "9    0.23  Very Good     H     VS1   59.4   61.0    338  4.00  4.05  2.39\n",
      "10   0.30       Good     J     SI1   64.0   55.0    339  4.25  4.28  2.73\n",
      "11   0.23      Ideal     J     VS1   62.8   56.0    340  3.93  3.90  2.46\n",
      "12   0.22    Premium     F     SI1   60.4   61.0    342  3.88  3.84  2.33\n",
      "13   0.31      Ideal     J     SI2   62.2   54.0    344  4.35  4.37  2.71\n",
      "14   0.20    Premium     E     SI2   60.2   62.0    345  3.79  3.75  2.27\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "diamonds = pd.read_csv(\"diamonds.csv\")\n",
    "result = diamonds.head(15)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a list of diamonds with several different pieces of information about them, such as the number of carats, the cut, color, clarity, and so on...\n",
    "\n",
    "You will be trying to predict `price` using linear regression using a subset of the other diamond features.\n",
    "\n",
    "&#9989; **Question 3.2 (3 points)**: Create two arrays and/or dataframes from the data you just loaded, one of them called `labels`, the other one called `features`. `labels` should **only** include the `price` column, while `features` should include **just the following columns**:\n",
    "* `carat`\n",
    "* `depth`\n",
    "* `table`\n",
    "* `x`\n",
    "* `y`\n",
    "* `z`\n",
    "\n",
    "You should be able to create a new dataframe with only these columns or drop all the columns that should *not* be in your `features` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         326\n",
      "1         326\n",
      "2         327\n",
      "3         334\n",
      "4         335\n",
      "         ... \n",
      "53935    2757\n",
      "53936    2757\n",
      "53937    2757\n",
      "53938    2757\n",
      "53939    2757\n",
      "Name: price, Length: 53940, dtype: int64\n",
      "       carat  depth  table     x     y     z\n",
      "0       0.23   61.5   55.0  3.95  3.98  2.43\n",
      "1       0.21   59.8   61.0  3.89  3.84  2.31\n",
      "2       0.23   56.9   65.0  4.05  4.07  2.31\n",
      "3       0.29   62.4   58.0  4.20  4.23  2.63\n",
      "4       0.31   63.3   58.0  4.34  4.35  2.75\n",
      "...      ...    ...    ...   ...   ...   ...\n",
      "53935   0.72   60.8   57.0  5.75  5.76  3.50\n",
      "53936   0.72   63.1   55.0  5.69  5.75  3.61\n",
      "53937   0.70   62.8   60.0  5.66  5.68  3.56\n",
      "53938   0.86   61.0   58.0  6.15  6.12  3.74\n",
      "53939   0.75   62.2   55.0  5.83  5.87  3.64\n",
      "\n",
      "[53940 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "labels = diamonds[\"price\"]\n",
    "print(labels)\n",
    "features1 = diamonds.drop(\"cut\", axis = 'columns')\n",
    "features2 = features1.drop(\"color\", axis = 'columns')\n",
    "features3 = features2.drop(\"clarity\", axis = 'columns')\n",
    "features = features3.drop(\"price\", axis = 'columns')\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the labels and features to fit, we will use the `statsmodels` `OLS` model to fit it. \n",
    "\n",
    "&#9989; **Question 3.3 (2 point)**: Before we do this, **add a column of constants (set to 1.0) to the `features`**. There is a `statsmodel` function you saw in class that allows you to do that. Call this new data structure `features_const`. (If you cannot figure this out, you can use `features` instead of `features_const` for the next questions.) Print/display `features_const` to make sure the new column exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       const  carat  depth  table     x     y     z\n",
      "0        1.0   0.23   61.5   55.0  3.95  3.98  2.43\n",
      "1        1.0   0.21   59.8   61.0  3.89  3.84  2.31\n",
      "2        1.0   0.23   56.9   65.0  4.05  4.07  2.31\n",
      "3        1.0   0.29   62.4   58.0  4.20  4.23  2.63\n",
      "4        1.0   0.31   63.3   58.0  4.34  4.35  2.75\n",
      "...      ...    ...    ...    ...   ...   ...   ...\n",
      "53935    1.0   0.72   60.8   57.0  5.75  5.76  3.50\n",
      "53936    1.0   0.72   63.1   55.0  5.69  5.75  3.61\n",
      "53937    1.0   0.70   62.8   60.0  5.66  5.68  3.56\n",
      "53938    1.0   0.86   61.0   58.0  6.15  6.12  3.74\n",
      "53939    1.0   0.75   62.2   55.0  5.83  5.87  3.64\n",
      "\n",
      "[53940 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "### Put your code here\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from IPython.display import HTML\n",
    "features_with_const = sm.add_constant(features)\n",
    "print(features_with_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will perform the actual fit.\n",
    "\n",
    "&#9989; **Question 3.4 (3 points)**: Using `statsmodels` `OLS`, perform a fit using `labels` (containing `price`) as the quantity to fit (y) and fit it to the `features_const` (X). Once the fit is done print the fit `summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept and slope are: const    20849.316413\n",
      "carat    10686.309081\n",
      "depth     -203.154052\n",
      "table     -102.445652\n",
      "x        -1315.667842\n",
      "y           66.321602\n",
      "z           41.627697\n",
      "dtype: float64\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.859\n",
      "Model:                            OLS   Adj. R-squared:                  0.859\n",
      "Method:                 Least Squares   F-statistic:                 5.486e+04\n",
      "Date:                Wed, 13 Dec 2023   Prob (F-statistic):               0.00\n",
      "Time:                        13:29:11   Log-Likelihood:            -4.7090e+05\n",
      "No. Observations:               53940   AIC:                         9.418e+05\n",
      "Df Residuals:                   53933   BIC:                         9.419e+05\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       2.085e+04    447.562     46.584      0.000       2e+04    2.17e+04\n",
      "carat       1.069e+04     63.201    169.085      0.000    1.06e+04    1.08e+04\n",
      "depth       -203.1541      5.504    -36.910      0.000    -213.942    -192.366\n",
      "table       -102.4457      3.084    -33.216      0.000    -108.491     -96.401\n",
      "x          -1315.6678     43.070    -30.547      0.000   -1400.086   -1231.250\n",
      "y             66.3216     25.523      2.599      0.009      16.296     116.347\n",
      "z             41.6277     44.305      0.940      0.347     -45.210     128.465\n",
      "==============================================================================\n",
      "Omnibus:                    14093.399   Durbin-Watson:                   1.249\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           373568.966\n",
      "Skew:                           0.674   Prob(JB):                         0.00\n",
      "Kurtosis:                      15.822   Cond. No.                     5.91e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.91e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "### Put your code here\n",
    "model = sm.OLS(labels, features_with_const)\n",
    "results = model.fit()\n",
    "print(\"Intercept and slope are:\", results.params)\n",
    "print(results.summary() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.5 (2 points)**: Which feature would you say contributes the least to the fit result and/or is the least important? Make sure to justify your answer with a sentence or two. If you were unable to successfully add the constant term and the results do not indicate a least important feature, explain why that might be. Then for Question 3.6, just choose a feature to remove."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> The least important feature is z. It has a p-value of .347 which is above all used confidence levels of .1,.05, and .01. This means it is not statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.6 (2 points)**: Now **run the fit again, but with the \"least important\" feature you identified in Q3.5 removed**. Make sure your new features still include the `constant` column (unless that happens to be the least important feature). **Print the fit `summary()`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       const  carat  depth  table     x     y\n",
      "0        1.0   0.23   61.5   55.0  3.95  3.98\n",
      "1        1.0   0.21   59.8   61.0  3.89  3.84\n",
      "2        1.0   0.23   56.9   65.0  4.05  4.07\n",
      "3        1.0   0.29   62.4   58.0  4.20  4.23\n",
      "4        1.0   0.31   63.3   58.0  4.34  4.35\n",
      "...      ...    ...    ...    ...   ...   ...\n",
      "53935    1.0   0.72   60.8   57.0  5.75  5.76\n",
      "53936    1.0   0.72   63.1   55.0  5.69  5.75\n",
      "53937    1.0   0.70   62.8   60.0  5.66  5.68\n",
      "53938    1.0   0.86   61.0   58.0  6.15  6.12\n",
      "53939    1.0   0.75   62.2   55.0  5.83  5.87\n",
      "\n",
      "[53940 rows x 6 columns]\n",
      "Intercept and slope are: const    20702.946665\n",
      "carat    10686.706903\n",
      "depth     -200.717571\n",
      "table     -102.490091\n",
      "x        -1293.542258\n",
      "y           69.575326\n",
      "dtype: float64\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.859\n",
      "Model:                            OLS   Adj. R-squared:                  0.859\n",
      "Method:                 Least Squares   F-statistic:                 6.583e+04\n",
      "Date:                Wed, 13 Dec 2023   Prob (F-statistic):               0.00\n",
      "Time:                        13:34:51   Log-Likelihood:            -4.7090e+05\n",
      "No. Observations:               53940   AIC:                         9.418e+05\n",
      "Df Residuals:                   53934   BIC:                         9.419e+05\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        2.07e+04    419.575     49.343      0.000    1.99e+04    2.15e+04\n",
      "carat       1.069e+04     63.199    169.095      0.000    1.06e+04    1.08e+04\n",
      "depth       -200.7176      4.855    -41.344      0.000    -210.233    -191.202\n",
      "table       -102.4901      3.084    -33.234      0.000    -108.534     -96.446\n",
      "x          -1293.5423     36.063    -35.869      0.000   -1364.225   -1222.859\n",
      "y             69.5753     25.287      2.751      0.006      20.013     119.138\n",
      "==============================================================================\n",
      "Omnibus:                    14094.014   Durbin-Watson:                   1.250\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           373375.505\n",
      "Skew:                           0.675   Prob(JB):                         0.00\n",
      "Kurtosis:                      15.818   Cond. No.                     5.53e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.53e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "### Put your code here\n",
    "features_no_z = features.drop(\"z\", axis = 'columns')\n",
    "features_no_z_with_const = sm.add_constant(features_no_z)\n",
    "print(features_no_z_with_const)\n",
    "model = sm.OLS(labels, features_no_z_with_const)\n",
    "results = model.fit()\n",
    "print(\"Intercept and slope are:\", results.params)\n",
    "print(results.summary() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.7 (2 points)**: Comment on the difference in fit quality between the two fits you just performed. Is one much better or worse than the other? Is the difference what you expected? Explain how you judged the quality given the fit statistics you printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> The adjusted R-squared values are the same for both models. This means that adding/removing the z feature had no impact on the fit of the graph. This is expected, since the P-value showed z to not be statistically significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 3**\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Perform a support vector machine (SVM) classification on data (16 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the exam, you will be using a dataset that is based on some precise measurements of a variety of dry beans to try and classify beans by their type. You can download the dataset from here:\n",
    "\n",
    "`https://raw.githubusercontent.com/msu-cmse-courses/cmse202-supplemental-data/main/data/Dry_Bean_Dataset.csv`\n",
    "\n",
    "&#9989; **Question 4.1 (1 point)**: **Load the `Dry_Bean_Dataset.csv`.** Display the first few lines of the loaded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to perform **classification**. We will try to see if we can classify the bean type using the properties that are given. We will need perform a train-test split on the data first.\n",
    "\n",
    "&#9989; **Question 4.2 (3 points)**: **Create two data structures** (e.g. dataframes) from your table: one called `labels` containing **only** the values from the `Class` column and one called `features` containing **everything but** the `Class` column.\n",
    "\n",
    "Then, perform a **train-test-split** using functions we used in class. Use a `train_size` of `0.75` and `random_state` of `42`. You should now have a training and a testing set with \"labels\" and \"features\" each.\n",
    "\n",
    "**Syntax Note:** if you are using Pandas dataframes for creating and storing your `labels` variable, you will need to make sure to use `['Class']` for the single-column selection, not `[['Class']]` as the latter will create a list of single-entry lists that the classification code you are going to use later will not like! If you run into and issue and you think it might be related to this, notify your instructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.3 (6 points)**: **Fit an SVM classifier (using the `sklearn` `SVC` class) to the dataset.** Use a `linear` kernel and set the hyper-parameter `C=1.0`. Then **fit your *training* set** and use the resulting fit to **predict your the *testing* set** so you get predicted labels for the testing set. Finally, print the fit statistics using `confusion_matrix` and `classification_report` (if you prefer the visual plot version of the confusion matrix, you can use `ConfusionMatrixDisplay` from `sklearn.metrics` instead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.4 (3 points)**: Interpret the output of your classification report and the confusion matrix by answering these three questions (provide at least 1 or 2 sentences each for full credit): \n",
    "* Explain in a few sentences what you observe in the confusion matrix. \n",
    "* Would you consider this a good or a bad classifier?\n",
    "* Which quantity from the classification report did you use to make this judgement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> Do This - Erase the contents of this cell an put your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.5 (3 points)**: We have been using machine learning \"jargon\" in this section and in class. In a few sentences each explain the following concepts:\n",
    "* What are \"labels\" and \"features\"?\n",
    "* Why do we need \"training sets\" and \"testing sets\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> Do This - Erase the contents of this cell an put your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 4**\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You're done! Congrats on finishing your CMSE 202 Final!\n",
    "\n",
    "Make sure all of your changes to your repository are committed and pushed to GitHub. Also upload a copy of this notebook to the dropbox on D2L in case something went wrong with your repository or if you couldn't get the repository to work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
